{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# train\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# load data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,),(0.3081,)),  # mean value = 0.1307, standard deviation value = 0.3081\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './MNIST'\n",
    "\n",
    "training_set = datasets.MNIST(root = data_path, train= True, download=True, transform= transform)\n",
    "testing_set = datasets.MNIST(root = data_path, train= False, download=True, transform= transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "* design a neural network that consists of three `fully connected layers` with an activation function of `Sigmoid`\n",
    "* the activation function for the output layer is `LogSoftmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classification, self).__init__()\n",
    "        \n",
    "        # construct layers for a neural network\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=20*20),\n",
    "            nn.Sigmoid(),\n",
    "        ) \n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(in_features=20*20, out_features=10*10),\n",
    "            nn.Sigmoid(),\n",
    "        ) \n",
    "        self.classifier3 = nn.Sequential(\n",
    "            nn.Linear(in_features=10*10, out_features=10),\n",
    "            nn.LogSoftmax(dim=1),\n",
    "        ) \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs):                 # [batchSize, 1, 28, 28]\n",
    "        x = inputs.view(inputs.size(0), -1)    # [batchSize, 28*28]\n",
    "        x = self.classifier1(x)                # [batchSize, 20*20]\n",
    "        x = self.classifier2(x)                # [batchSize, 10*10]\n",
    "        out = self.classifier3(x)              # [batchSize, 10]\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "* use a stochastic gradient descent algorithm with different mini-batch sizes of 32, 64, 128\n",
    "* use a constant learning rate for all the mini-batch sizes\n",
    "* do not use any regularization algorithm such as `dropout` or `weight decay`\n",
    "* compute the average loss and the average accuracy for all the mini-batches within each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(log_pred, y_true):\n",
    "    y_pred = torch.argmax(log_pred, dim=1)\n",
    "    return (y_pred == y_true).to(torch.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-e7bf3875f3f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mX_test_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0my_test_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-5b5caeb0162f>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                 \u001b[1;31m# [batchSize, 1, 28, 28]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# [batchSize, 28*28]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m                \u001b[1;31m# [batchSize, 20*20]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m                \u001b[1;31m# [batchSize, 10*10]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m              \u001b[1;31m# [batchSize, 10]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1672\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1673\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1674\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1676\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "lr=0.5\n",
    "n_epochs = 20\n",
    "\n",
    "no_cuda = True\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=testing_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "classifier = classification().to(device)\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "accuracy_stats = {\n",
    "    'train': [],\n",
    "    \"test\": []\n",
    "}\n",
    "loss_stats = {\n",
    "    'train': [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    # TRAINING\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    \n",
    "    classifier.train()\n",
    "    \n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_train_pred = classifier(X_train_batch)\n",
    "        \n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = accuracy(y_train_pred, y_train_batch)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        test_epoch_loss = 0\n",
    "        test_epoch_acc = 0\n",
    "        \n",
    "        classifier.eval()\n",
    "        \n",
    "        for X_test_batch, y_test_batch in test_loader:\n",
    "            X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
    "        \n",
    "            y_test_pred = classifier(X_test_batch)\n",
    "            \n",
    "            test_loss = criterion(y_test_pred, y_test_batch)\n",
    "            test_acc = accuracy(y_test_pred, y_test_batch)\n",
    "            \n",
    "            test_epoch_loss += test_loss.item()\n",
    "            test_epoch_acc += test_acc.item()\n",
    "            \n",
    "#     # VALIDATION    \n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         val_epoch_loss = 0\n",
    "#         val_epoch_acc = 0\n",
    "        \n",
    "#         classifier.eval()\n",
    "#         for X_val_batch, y_val_batch in test_loader:\n",
    "#             X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            \n",
    "#             y_val_pred = classifier(X_val_batch)\n",
    "                        \n",
    "#             val_loss = criterion(y_val_pred, y_val_batch)\n",
    "#             val_acc = multi_acc(y_val_pred, y_val_batch)\n",
    "            \n",
    "#             val_epoch_loss += val_loss.item()\n",
    "#             val_epoch_acc += val_acc.item()\n",
    "            \n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['test'].append(test_epoch_loss/len(test_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['test'].append(test_epoch_acc/len(test_loader))\n",
    "         \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281, 0.0648531833662281]\n"
     ]
    }
   ],
   "source": [
    "print(loss_stats['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1,figsize=(9,9))\n",
    "plt.plot(np.array(range(n_epochs)), loss_stats['train'], c='r', label='train_loss')\n",
    "plt.plot(np.array(range(n_epochs)), loss_stats['test'], label='test_loss')\n",
    "plt.legend()\n",
    "plt.title('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Plot the training and testing losses with a batch size of 32 [4pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plot the training and testing accuracies with a batch size of 32 [4pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Plot the training and testing losses with a batch size of 64 [4pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plot the training and testing accuracies with a batch size of 64 [4pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the training and testing losses with a batch size of 128 [4pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Plot the training and testing accuracies with a batch size of 128 [4pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Print the loss at convergence with different mini-batch sizes [3pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Print the accuracy at convergence with different mini-batch sizes [3pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
